### Introduction
This project was completed in July 2022 with the goal of studying a dice game called Dudo and figuring out the best strategies to play it. Dudo is a game where two players roll dice and make claims about what they have rolled collectively. The catch is that players can bluff and hide their actual dice rolls, making it a game of deception and strategy.

### Game Description
In Dudo, each round starts with both players rolling a die secretly and keeping the results hidden from their opponent. Then, the first player makes a claim about what they have rolled collectively. For example, they might say, "I think there are two ⚂'s". The next player then has to make a claim that is stronger, like saying, "I think there are two ⚃'s". Players keep taking turns and increasing the claim until one player challenges the previous claim by saying "dudo." When this happens, both players reveal their dice, and if the challenged claim is stronger than what's on the table, the challenger wins; otherwise, they lose.

### Methodology
To determine the best strategies for playing Dudo, we used a method called counterfactual regret minimization. The method is outlined in [this](https://www.ma.imperial.ac.uk/~dturaev/neller-lanctot.pdf) paper, where the application to Dudo is left as an excerise.

When playing Dudo, there are many possible strategies a player can employ. A strategy in this context refers to a set of rules or guidelines that dictate how a player should act in different situations. These strategies can be probabilistic, meaning they involve making decisions based on probabilities rather than fixed actions. For example, a strategy might recommend making certain claims with higher probabilities and others with lower probabilities based on the player's evaluation of the current situation.

Counterfactual regret centres around quantifying the value of a specific point in the game when a player is about to choose an action. We compare the value of each possible action at that point with the value the player would expect to receive under their current strategy. This process allows us to determine the "regret" associated with each possible action. Regret, in this context, refers to the difference in value between the outcomes achieved by a particular action and the outcomes achieved by the action that the player's current strategy prescribes. By calculating and comparing regrets for each possible action, we gain insights into the potential improvements that can be made to the player's strategy. It has been demonstrated that if both players update their strategies in this way, the average of their strategies will eventually converge to being optimal.

### Algorithm
In dudo, each player has their own unique perspective at different points in the game when they need to make a decision. These perspectives are organised into information sets that are associated with the specific player. Information sets group together game states that are indistinguishable to a particular player. This means that from the player's perspective, they cannot differentiate between these game states because they have incomplete information about the game. These information sets can be naturally structured as vertices of a directed acyclic graph (DAG). The graph represents the sequential structure of the game, where each vertex corresponds to an information set at a specific point in the game. The ordering of the vertices follows the sequential progression of the game, reflecting the player's decision points and the information available to them at each stage.

FSICFR, or Fixed-Strategy Iteration Counterfactual Regret Minimization, updates strategies through a two-step iterative process. In each iteration, the values of each player's die are randomised, and the algorithm operates on a directed acyclic graph (DAG) of information sets.

In the first step, called the forward pass, FSICFR calculates the probabilities of reaching each node in the graph based on the players' current strategies. In the second step, called the backward pass, FSICFR computes the utility of each node by combining the reach probabilities with the utility of previous nodes. Starting from the terminal nodes, which represent wins or losses, the utility values propagate backward through the graph. This process allows the algorithm to determine the regret associated with each action under the current strategy, and adjust it accordingly.

During the training iterations, FSICFR maintains a sum of the strategies used by the players. This sum is used to calculate the average strategy across all iterations. It is this average that converges to the optimal strategy.